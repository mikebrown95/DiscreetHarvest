{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30505a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Starting Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-10-10T13:23:39.239638-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Omniglot not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.241980-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Omniglot.__len__ not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.247332-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Places365 not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.251732-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Places365.__len__ not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.256605-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.GaussianBlur not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.263271-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.ConvertImageDtype not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.271918-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.296323-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.305107-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.307647-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.gaussian_blur not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.309191-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.310828-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.313241-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.rgb_to_grayscale not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:39.315084-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.0a0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following code to your Duet Partner!\n",
      "\n",
      "import syft as sy\n",
      "duet = sy.join_duet(loopback=True)\n",
      "\n",
      "â™«â™«â™« > Connecting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertbrown/opt/anaconda3/envs/farm/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "/Users/robertbrown/opt/anaconda3/envs/farm/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n",
      "[2021-10-10T13:23:49.909652-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Omniglot not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.910656-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Omniglot.__len__ not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.911413-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Places365 not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.912146-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Places365.__len__ not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.915584-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.GaussianBlur not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.917448-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.ConvertImageDtype not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.919177-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.920459-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.923270-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.926022-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.gaussian_blur not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.928054-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.930040-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.931311-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.rgb_to_grayscale not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:49.933063-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.226207-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Omniglot not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.227214-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Omniglot.__len__ not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.228049-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Places365 not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.228994-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.datasets.Places365.__len__ not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.234852-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.GaussianBlur not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.237418-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.ConvertImageDtype not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.239071-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.adjust_sharpness not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.240251-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.autocontrast not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.241995-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.equalize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.243236-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.gaussian_blur not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.244678-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.invert not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.246359-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.posterize not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.250229-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.rgb_to_grayscale not supported in 0.8.0a0\n",
      "[2021-10-10T13:23:50.253607-0400][CRITICAL][logger]][12628] Skipping torchvision.torchvision.transforms.functional.solarize not supported in 0.8.0a0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > DUET LIVE STATUS  *  Objects: 8  Requests: 0   Messages: 3013  Request Handlers: 1                                                          \r"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet = sy.launch_duet(loopback=True)\n",
    "\n",
    "# Notes: Review layers of model for possible improvement, add tags to iformation . Add notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3194ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.requests.add_handler(action=\"accept\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8340f414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d891c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â™«â™«â™« > DUET LIVE STATUS  -  Objects: 0  Requests: 0   Messages: 4  Request Handlers: 1                                \r"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import torch as th\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c21094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing\n",
    "\n",
    "df = pd.read_csv(\"wheat-2013-supervised.csv\")\n",
    "df1 = pd.read_csv(\"wheat-2014-supervised.csv\")\n",
    "df = pd.concat([df, df1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927c8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['Yield'] <= 31),\n",
    "    (df['Yield'] > 31)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [0,1]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['Yield_Cat'] = np.select(conditions, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21526977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EstDistEquator'] = df['Latitude'] * 69\n",
    "\n",
    "data_new = df[['EstDistEquator','precipTypeIsOther','temperatureMax','NDVI','visibility','dewPoint','pressure','humidity','cloudCover','windSpeed', 'Yield_Cat' ]]\n",
    "\n",
    "data_new = data_new.dropna(axis=0)\n",
    "\n",
    "y = data_new[['Yield_Cat']]\n",
    "x = data_new.drop(['Yield_Cat'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96455767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature data\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af0d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data and labels to tensors\n",
    "\n",
    "x = num_pipeline.fit_transform(x)\n",
    "\n",
    "x = th.FloatTensor(x)\n",
    "\n",
    "y = y.to_numpy()\n",
    "\n",
    "y = th.FloatTensor(y).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee8d5662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([359427])\n"
     ]
    }
   ],
   "source": [
    "# Labels vector shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4daf0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide information about data to be sent to the Data Scientist \n",
    "x = x.tag(\"Farm sensor data\")\n",
    "y = y.tag(\"Wheat yield labels\")\n",
    "\n",
    "x = x.describe(\n",
    "    \"This is a dataset for wheat yield of 359,427 examples using 10 features w/ IoT sensor data.\"\n",
    ")\n",
    "y = y.describe(\"Labels for wheat yield. 0 = low yield. 1 = high yield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d3912db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send pointers to the data to the Data Scientist \n",
    "\n",
    "data_pointer = x.send(duet, pointable=True)\n",
    "target_pointer = y.send(duet, pointable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609e3134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<syft.proxy.torch.TensorPointer object at 0x7fa7e3a3eb80>, <syft.proxy.torch.TensorPointer object at 0x7fa7ceffb1f0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the sent information (Pointers to tensor objects)\n",
    "duet.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14ff7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes, accept all requests from Data Scientist \n",
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5343e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
